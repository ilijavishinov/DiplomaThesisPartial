{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "from comet_ml import Experiment\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "from keras_metrics_module import f1_1_func, f1_0_func, recall_func, precision_func, f1_macro_func\n",
    "import itertools\n",
    "import pandas as pd\n",
    "from modules.testing_module import metrics_report\n",
    "from modules import json_module, h5py_module, dirs_module\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout, BatchNormalization, ReLU\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras_tuner as kt\n",
    "\n",
    "\n",
    "dirs_module.create_directory('saved_models', warn_exists = False)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "HZ = '32kHz'\n",
    "SPLIT_ID = 'S3'\n",
    "REGIME = ''\n",
    "FEATURE = f'HostService_{HZ}_vibration_1'\n",
    "DURATION = '01S'\n",
    "ADDITIONAL_INFO = 'CNN'\n",
    "COMET_PROJECT = 'bayesian'\n",
    "EXPERIMENT_ID = f'{SPLIT_ID}_{DURATION}_{FEATURE}_{REGIME}_{ADDITIONAL_INFO}'\n",
    "\n",
    "data_dir = r'data\\s3_01s_oversampling001005_32HZ'\n",
    "\n",
    "healthy_train = ['K001','K002','K003']\n",
    "real_damage_train = ['KA04','KA15','KA22','KA30','KB23','KB27','KI04','KI17']\n",
    "artificial_damage_train = ['KA01','KA05','KA07','KI01','KI03']\n",
    "train_bearing_codes = healthy_train + artificial_damage_train + real_damage_train"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "(426480, 3200, 1)"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reading_files_hz = '64kHz'\n",
    "first_read = True\n",
    "for bearing_code in train_bearing_codes:\n",
    "\n",
    "    if first_read:\n",
    "        first_read = False\n",
    "        x_train = np.load(f'{data_dir}/x_train_{REGIME}{bearing_code}_{FEATURE.replace(HZ,reading_files_hz)}.npy', allow_pickle = True)\n",
    "        y_train = np.load(f'{data_dir}/y_train_{REGIME}{bearing_code}.npy', allow_pickle = True)\n",
    "    else:\n",
    "        x_train = np.concatenate(\n",
    "            [x_train, np.load(f'{data_dir}/x_train_{REGIME}{bearing_code}_{FEATURE.replace(HZ,reading_files_hz)}.npy', allow_pickle = True)],\n",
    "            axis = 0)\n",
    "        y_train = np.concatenate(\n",
    "            [y_train, np.load(f'{data_dir}/y_train_{REGIME}{bearing_code}.npy', allow_pickle = True)],\n",
    "            axis = 0)\n",
    "\n",
    "x_train = x_train.reshape((x_train.shape[0], x_train.shape[1], 1))\n",
    "INPUT_SHAPE = (x_train.shape[1], x_train.shape[2])\n",
    "x_train.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "(40521, 3200, 1)"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test = np.load(f'{data_dir}/x_test_{REGIME}{FEATURE.replace(HZ,reading_files_hz)}.npy', allow_pickle = True)\n",
    "x_test = x_test.reshape((x_test.shape[0], x_test.shape[1], 1))\n",
    "y_test = np.load(f'{data_dir}/y_test{REGIME}.npy', allow_pickle = True)\n",
    "x_test.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "(121840, 3200, 1)"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_val = np.load(f'{data_dir}/x_val_{REGIME}{FEATURE.replace(HZ,reading_files_hz)}.npy', allow_pickle = True)\n",
    "x_val = x_val.reshape((x_val.shape[0], x_val.shape[1], 1))\n",
    "y_val = np.load(f'{data_dir}/y_val{REGIME}.npy', allow_pickle = True)\n",
    "x_val.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "0    228360\n1    198120\ndtype: int64"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_value_counts = pd.Series(list(y_train)).value_counts()\n",
    "class_weight = {\n",
    "    0: y_value_counts[1] / y_value_counts[0],\n",
    "    1: 1\n",
    "}\n",
    "y_value_counts"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "y_train = tf.keras.utils.to_categorical(y_train)\n",
    "y_test = tf.keras.utils.to_categorical(y_test)\n",
    "y_val = tf.keras.utils.to_categorical(y_val)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "search_space = dict(\n",
    "    wide_layer_kernel_size = [16,32],\n",
    "    wide_layer_num_kernels = [16,32],\n",
    "    num_narrow_cnn_layers = [2,3],\n",
    "    narrow_layers_kernel_size = [8,16],\n",
    "    narrow_layers_num_kernels = [16,32,64],\n",
    "\n",
    "    num_dense_layers = [2],\n",
    "    dense_layers_num_nodes = [64],\n",
    "    dense_layers_shrinkage_factor = [0.5],\n",
    "\n",
    "    dropout = [True],\n",
    "    batch_norm = [True],\n",
    "\n",
    "    batch_size = [256],\n",
    "    loss_name = ['binary_crossentropy', 'categorical_hinge'],\n",
    "    optimizer_name = ['adam'],\n",
    "    learning_rate = [0.01, 0.25, 0.5],\n",
    "    epochs = [5],\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "\n",
    "    wide_layer_kernel_size = hp.Int('wide_layer_num_kernels',2,512)\n",
    "    wide_layer_num_kernels = hp.Int('wide_layer_num_kernels',4,64)\n",
    "    # num_narrow_cnn_layers = hp.Int('num_narrow_cnn_layers',1,5)\n",
    "    # narrow_layers_kernel_size = hp.Int('narrow_layers_kernel_size',4,128)\n",
    "    # narrow_layers_num_kernels = hp.Int('narrow_layers_num_kernels',4,64)\n",
    "    num_dense_layers = hp.Int('num_dense_layers',1,3)\n",
    "    dense_layers_num_nodes = hp.Int('dense_layers_num_nodes',16,128)\n",
    "    dense_layers_shrinkage_factor = 0.75\n",
    "    optimizer_name = 'adam'\n",
    "    learning_rate = hp.Choice('learning_rate', [0.001, 0.01, 0.1, 0.25, 0.5])\n",
    "    loss_name = 'categorical_crossentropy'\n",
    "    dropout = False\n",
    "    batch_norm = hp.Choice('batch_norm', [True, False])\n",
    "\n",
    "    layers_list = list()\n",
    "    layers_list.append(\n",
    "        Conv1D(filters=wide_layer_num_kernels,\n",
    "           kernel_size=wide_layer_kernel_size,\n",
    "           # strides = int(wide_layer_kernel_size/4),\n",
    "           input_shape=INPUT_SHAPE,\n",
    "           padding = 'same')\n",
    "    )\n",
    "    layers_list.append(ReLU())\n",
    "    if batch_norm:\n",
    "        layers_list.append(BatchNormalization())\n",
    "    layers_list.append(MaxPooling1D(pool_size=4, padding=\"same\"))\n",
    "\n",
    "    # for narrow_layer_number in range(1,num_narrow_cnn_layers+1):\n",
    "    #     layers_list.append(\n",
    "    #         Conv1D(filters=narrow_layers_num_kernels,\n",
    "    #                kernel_size=(narrow_layers_kernel_size,),\n",
    "    #                strides = int(wide_layer_kernel_size/2),\n",
    "    #                padding = 'same')\n",
    "    #     )\n",
    "    #     layers_list.append(ReLU())\n",
    "    #     if batch_norm:\n",
    "    #         layers_list.append(BatchNormalization())\n",
    "    #     layers_list.append(MaxPooling1D(pool_size=2, padding=\"same\"))\n",
    "\n",
    "    layers_list.append(Flatten())\n",
    "\n",
    "    dense_layer_current_num_nodes = dense_layers_num_nodes * (1/dense_layers_shrinkage_factor)\n",
    "    for dense_layer_number in range(1,num_dense_layers+1):\n",
    "        dense_layer_current_num_nodes = dense_layer_current_num_nodes * dense_layers_shrinkage_factor\n",
    "        layers_list.append(Dense(dense_layer_current_num_nodes))\n",
    "        layers_list.append(ReLU())\n",
    "        if batch_norm:\n",
    "            layers_list.append(BatchNormalization())\n",
    "        if dropout:\n",
    "            layers_list.append(Dropout(0.1))\n",
    "    if dropout:\n",
    "        layers_list = layers_list[:-1]\n",
    "\n",
    "\n",
    "    layers_list.append(Dense(2, activation='softmax'))\n",
    "\n",
    "    if optimizer_name.lower() == 'adam':\n",
    "        optimizer = tf.optimizers.Adam(learning_rate = learning_rate)\n",
    "\n",
    "    built_model = Sequential(layers_list)\n",
    "    built_model.compile(loss=loss_name, optimizer=optimizer,\n",
    "                        metrics=['accuracy', f1_macro_func, f1_1_func, f1_0_func, recall_func, precision_func])\n",
    "    tf.keras.utils.plot_model(built_model, to_file='model.pdf', show_shapes=True)\n",
    "    return built_model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "# try:\n",
    "experiment = Experiment(\n",
    "    api_key = 'A8Lg71j9LtIrsv0deBA0DVGcR',\n",
    "    project_name = COMET_PROJECT,\n",
    "    workspace = 'diploma',\n",
    "    auto_output_logging = 'native',\n",
    ")\n",
    "experiment.set_name(f\"Bayesian\")\n",
    "experiment.add_tags(EXPERIMENT_ID.split('_'))\n",
    "\n",
    "tuner = kt.BayesianOptimization(\n",
    "    build_model,\n",
    "    objective = kt.Objective(f1_macro_func, direction=\"max\"),\n",
    "    max_trials=1000,\n",
    "    executions_per_trial=2,\n",
    "    directory=\"keras_tuner_logs\",\n",
    "    project_name=\"initial_val\",\n",
    ")\n",
    "\n",
    "with experiment.train():\n",
    "    tuner.search(x_train, y_train,\n",
    "                 epochs = 10,\n",
    "                 class_weight = class_weight,\n",
    "                 verbose = 10,\n",
    "                 validation_data = (x_val, y_val))\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "results_list = list()\n",
    "models_dir = 'saved_models'\n",
    "import os\n",
    "for model_file in os.listdir(models_dir):\n",
    "    model_i = tf.keras.models.load_model(f'{models_dir}/{model_file}',\n",
    "            custom_objects = {\n",
    "                'f1_macro_func':f1_macro_func,\n",
    "                'f1_1_func':f1_1_func,\n",
    "                'f1_0_func':f1_0_func,\n",
    "                'precision_func':precision_func,\n",
    "                'recall_func':recall_func\n",
    "             })\n",
    "\n",
    "    y_pred = model_i.predict(x_test)\n",
    "    y_pred = np.where(y_pred > 0.5, 1, 0).ravel()\n",
    "\n",
    "    test_metrics = metrics_report(y_test, y_pred)\n",
    "    print(test_metrics)\n",
    "    results_list.append(test_metrics)\n",
    "\n",
    "    for layer_i in model_i.layers:\n",
    "        try:\n",
    "            print(layer_i.kernel_size)\n",
    "        except:\n",
    "            pass"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pd.DataFrame(results_list).to_excel('results.xlsx')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%g\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}