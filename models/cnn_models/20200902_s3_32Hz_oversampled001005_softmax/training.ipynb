{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "from comet_ml import Experiment\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "from keras_metrics_module import f1_1_func, f1_0_func, recall_func, precision_func, f1_macro_func\n",
    "import itertools\n",
    "import pandas as pd\n",
    "from modules.testing_module import metrics_report\n",
    "from modules import json_module, h5py_module, dirs_module\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout, BatchNormalization, ReLU\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras_tuner as kt\n",
    "\n",
    "\n",
    "dirs_module.create_directory('saved_models', warn_exists = False)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "HZ = '32kHz'\n",
    "SPLIT_ID = 'S3'\n",
    "REGIME = ''\n",
    "FEATURE = f'HostService_{HZ}_vibration_1'\n",
    "DURATION = '01S'\n",
    "ADDITIONAL_INFO = 'CNN'\n",
    "COMET_PROJECT = 'bayesian'\n",
    "EXPERIMENT_ID = f'{SPLIT_ID}_{DURATION}_{FEATURE}_{REGIME}_{ADDITIONAL_INFO}'\n",
    "\n",
    "data_dir = r'F:\\40_diploma_thesis\\s3_01s_oversampling001005_32HZ'\n",
    "\n",
    "healthy_train = ['K001','K002','K003']\n",
    "real_damage_train = ['KA04','KA15','KA22','KA30','KB23','KB27','KI04','KI17']\n",
    "artificial_damage_train = ['KA01','KA05','KA07','KI01','KI03']\n",
    "train_bearing_codes = healthy_train + artificial_damage_train + real_damage_train"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "(426480, 3200, 1)"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reading_files_hz = '64kHz'\n",
    "first_read = True\n",
    "for bearing_code in train_bearing_codes:\n",
    "\n",
    "    if first_read:\n",
    "        first_read = False\n",
    "        x_train = np.load(f'{data_dir}/x_train_{REGIME}{bearing_code}_{FEATURE.replace(HZ,reading_files_hz)}.npy', allow_pickle = True)\n",
    "        y_train = np.load(f'{data_dir}/y_train_{REGIME}{bearing_code}.npy', allow_pickle = True)\n",
    "    else:\n",
    "        x_train = np.concatenate(\n",
    "            [x_train, np.load(f'{data_dir}/x_train_{REGIME}{bearing_code}_{FEATURE.replace(HZ,reading_files_hz)}.npy', allow_pickle = True)],\n",
    "            axis = 0)\n",
    "        y_train = np.concatenate(\n",
    "            [y_train, np.load(f'{data_dir}/y_train_{REGIME}{bearing_code}.npy', allow_pickle = True)],\n",
    "            axis = 0)\n",
    "\n",
    "x_train = x_train.reshape((x_train.shape[0], x_train.shape[1], 1))\n",
    "INPUT_SHAPE = (x_train.shape[1], x_train.shape[2])\n",
    "x_train.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "(40521, 3200, 1)"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test = np.load(f'{data_dir}/x_test_{REGIME}{FEATURE.replace(HZ,reading_files_hz)}.npy', allow_pickle = True)\n",
    "x_test = x_test.reshape((x_test.shape[0], x_test.shape[1], 1))\n",
    "y_test = np.load(f'{data_dir}/y_test{REGIME}.npy', allow_pickle = True)\n",
    "x_test.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "(121840, 3200, 1)"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_val = np.load(f'{data_dir}/x_val_{REGIME}{FEATURE.replace(HZ,reading_files_hz)}.npy', allow_pickle = True)\n",
    "x_val = x_val.reshape((x_val.shape[0], x_val.shape[1], 1))\n",
    "y_val = np.load(f'{data_dir}/y_val{REGIME}.npy', allow_pickle = True)\n",
    "x_val.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "0    228360\n1    198120\ndtype: int64"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_value_counts = pd.Series(list(y_train)).value_counts()\n",
    "class_weight = {\n",
    "    0: y_value_counts[1] / y_value_counts[0],\n",
    "    1: 1\n",
    "}\n",
    "y_value_counts"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "y_train = tf.keras.utils.to_categorical(y_train)\n",
    "y_test = tf.keras.utils.to_categorical(y_test)\n",
    "y_val = tf.keras.utils.to_categorical(y_val)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "search_space = dict(\n",
    "    wide_layer_kernel_size = [16,32],\n",
    "    wide_layer_num_kernels = [16,32],\n",
    "    num_narrow_cnn_layers = [2,3],\n",
    "    narrow_layers_kernel_size = [8,16],\n",
    "    narrow_layers_num_kernels = [16,32,64],\n",
    "\n",
    "    num_dense_layers = [2],\n",
    "    dense_layers_num_nodes = [64],\n",
    "    dense_layers_shrinkage_factor = [0.5],\n",
    "\n",
    "    dropout = [True],\n",
    "    batch_norm = [True],\n",
    "\n",
    "    batch_size = [256],\n",
    "    loss_name = ['binary_crossentropy', 'categorical_hinge'],\n",
    "    optimizer_name = ['adam'],\n",
    "    learning_rate = [0.01, 0.25, 0.5],\n",
    "    epochs = [5],\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "\n",
    "    wide_layer_kernel_size = hp.Int('wide_layer_num_kernels',2,512)\n",
    "    wide_layer_num_kernels = hp.Int('wide_layer_num_kernels',4,64)\n",
    "    # num_narrow_cnn_layers = hp.Int('num_narrow_cnn_layers',1,5)\n",
    "    # narrow_layers_kernel_size = hp.Int('narrow_layers_kernel_size',4,128)\n",
    "    # narrow_layers_num_kernels = hp.Int('narrow_layers_num_kernels',4,64)\n",
    "    num_dense_layers = hp.Int('num_dense_layers',1,3)\n",
    "    dense_layers_num_nodes = hp.Int('dense_layers_num_nodes',16,128)\n",
    "    dense_layers_shrinkage_factor = 0.75\n",
    "    optimizer_name = 'adam'\n",
    "    learning_rate = hp.Choice('learning_rate', [0.001, 0.01, 0.1, 0.25, 0.5])\n",
    "    loss_name = 'categorical_crossentropy'\n",
    "    dropout = False\n",
    "    batch_norm = hp.Choice('batch_norm', [True, False])\n",
    "\n",
    "    layers_list = list()\n",
    "    layers_list.append(\n",
    "        Conv1D(filters=wide_layer_num_kernels,\n",
    "           kernel_size=wide_layer_kernel_size,\n",
    "           # strides = int(wide_layer_kernel_size/4),\n",
    "           input_shape=INPUT_SHAPE,\n",
    "           padding = 'same')\n",
    "    )\n",
    "    layers_list.append(ReLU())\n",
    "    if batch_norm:\n",
    "        layers_list.append(BatchNormalization())\n",
    "    layers_list.append(MaxPooling1D(pool_size=4, padding=\"same\"))\n",
    "\n",
    "    # for narrow_layer_number in range(1,num_narrow_cnn_layers+1):\n",
    "    #     layers_list.append(\n",
    "    #         Conv1D(filters=narrow_layers_num_kernels,\n",
    "    #                kernel_size=(narrow_layers_kernel_size,),\n",
    "    #                strides = int(wide_layer_kernel_size/2),\n",
    "    #                padding = 'same')\n",
    "    #     )\n",
    "    #     layers_list.append(ReLU())\n",
    "    #     if batch_norm:\n",
    "    #         layers_list.append(BatchNormalization())\n",
    "    #     layers_list.append(MaxPooling1D(pool_size=2, padding=\"same\"))\n",
    "\n",
    "    layers_list.append(Flatten())\n",
    "\n",
    "    dense_layer_current_num_nodes = dense_layers_num_nodes * (1/dense_layers_shrinkage_factor)\n",
    "    for dense_layer_number in range(1,num_dense_layers+1):\n",
    "        dense_layer_current_num_nodes = dense_layer_current_num_nodes * dense_layers_shrinkage_factor\n",
    "        layers_list.append(Dense(dense_layer_current_num_nodes))\n",
    "        layers_list.append(ReLU())\n",
    "        if batch_norm:\n",
    "            layers_list.append(BatchNormalization())\n",
    "        if dropout:\n",
    "            layers_list.append(Dropout(0.1))\n",
    "    if dropout:\n",
    "        layers_list = layers_list[:-1]\n",
    "\n",
    "\n",
    "    layers_list.append(Dense(2, activation='softmax'))\n",
    "\n",
    "    if optimizer_name.lower() == 'adam':\n",
    "        optimizer = tf.optimizers.Adam(learning_rate = learning_rate)\n",
    "\n",
    "    built_model = Sequential(layers_list)\n",
    "    built_model.compile(loss=loss_name, optimizer=optimizer,\n",
    "                        metrics=['accuracy', f1_macro_func, f1_1_func, f1_0_func, recall_func, precision_func])\n",
    "    tf.keras.utils.plot_model(built_model, to_file='model.pdf', show_shapes=True)\n",
    "    return built_model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMET WARNING: As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\n",
      "COMET WARNING: Native output logging mode is not available, fallbacking on basic output logging\n",
      "COMET INFO: Experiment is live on comet.ml https://www.comet.ml/diploma/bayesian/27a43acec2b24c12928ad139939ae9cc\n",
      "\n",
      "COMET INFO: Ignoring automatic log_parameter('verbose') because 'keras:verbose' is in COMET_LOGGING_PARAMETERS_IGNORE\n",
      "COMET INFO: ignoring tensorflow summary log of metrics because of keras; set `comet_ml.loggers.tensorboard_logger.LOG_METRICS = True` to override\n",
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Search: Running Trial #1\n",
      "\n",
      "Hyperparameter    |Value             |Best Value So Far \n",
      "wide_layer_num_...|507               |?                 \n",
      "num_dense_layers  |2                 |?                 \n",
      "dense_layers_nu...|113               |?                 \n",
      "learning_rate     |0.25              |?                 \n",
      "batch_norm        |1                 |?                 \n",
      "\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Can save best model only with <function f1_macro_func at 0x0000023C8E616790> available, skipping.\n",
      "Epoch 2/10\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\finki\\40_diploma_thesis\\venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3441, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\ilija\\AppData\\Local\\Temp/ipykernel_11396/1010000241.py\", line 21, in <module>\n",
      "    tuner.search(x_train, y_train,\n",
      "  File \"d:\\finki\\40_diploma_thesis\\venv\\lib\\site-packages\\keras_tuner\\engine\\base_tuner.py\", line 176, in search\n",
      "    self.run_trial(trial, *fit_args, **fit_kwargs)\n",
      "  File \"d:\\finki\\40_diploma_thesis\\venv\\lib\\site-packages\\keras_tuner\\engine\\multi_execution_tuner.py\", line 90, in run_trial\n",
      "    history = self._build_and_fit_model(trial, fit_args, copied_fit_kwargs)\n",
      "  File \"d:\\finki\\40_diploma_thesis\\venv\\lib\\site-packages\\keras_tuner\\engine\\tuner.py\", line 149, in _build_and_fit_model\n",
      "    return model.fit(*fit_args, **fit_kwargs)\n",
      "  File \"d:\\finki\\40_diploma_thesis\\venv\\lib\\site-packages\\comet_ml\\monkey_patching.py\", line 317, in wrapper\n",
      "    return_value = original(*args, **kwargs)\n",
      "  File \"d:\\finki\\40_diploma_thesis\\venv\\lib\\site-packages\\keras\\engine\\training.py\", line 1184, in fit\n",
      "    tmp_logs = self.train_function(iterator)\n",
      "  File \"d:\\finki\\40_diploma_thesis\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\", line 885, in __call__\n",
      "    result = self._call(*args, **kwds)\n",
      "  File \"d:\\finki\\40_diploma_thesis\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\", line 917, in _call\n",
      "    return self._stateless_fn(*args, **kwds)  # pylint: disable=not-callable\n",
      "  File \"d:\\finki\\40_diploma_thesis\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\", line 3039, in __call__\n",
      "    return graph_function._call_flat(\n",
      "  File \"d:\\finki\\40_diploma_thesis\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\", line 1963, in _call_flat\n",
      "    return self._build_call_outputs(self._inference_function.call(\n",
      "  File \"d:\\finki\\40_diploma_thesis\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\", line 591, in call\n",
      "    outputs = execute.execute(\n",
      "  File \"d:\\finki\\40_diploma_thesis\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\", line 59, in quick_execute\n",
      "    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\finki\\40_diploma_thesis\\venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2061, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\finki\\40_diploma_thesis\\venv\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"d:\\finki\\40_diploma_thesis\\venv\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 248, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"d:\\finki\\40_diploma_thesis\\venv\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 281, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"C:\\Users\\ilija\\AppData\\Local\\Programs\\Python\\Python38\\lib\\inspect.py\", line 1503, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"C:\\Users\\ilija\\AppData\\Local\\Programs\\Python\\Python38\\lib\\inspect.py\", line 1461, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"C:\\Users\\ilija\\AppData\\Local\\Programs\\Python\\Python38\\lib\\inspect.py\", line 708, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"C:\\Users\\ilija\\AppData\\Local\\Programs\\Python\\Python38\\lib\\inspect.py\", line 746, in getmodule\n",
      "    f = module.__file__\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'NoneType' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "    \u001B[1;31m[... skipping hidden 1 frame]\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_11396/1010000241.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     20\u001B[0m \u001B[1;32mwith\u001B[0m \u001B[0mexperiment\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtrain\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 21\u001B[1;33m     tuner.search(x_train, y_train,\n\u001B[0m\u001B[0;32m     22\u001B[0m                  \u001B[0mepochs\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;36m10\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32md:\\finki\\40_diploma_thesis\\venv\\lib\\site-packages\\keras_tuner\\engine\\base_tuner.py\u001B[0m in \u001B[0;36msearch\u001B[1;34m(self, *fit_args, **fit_kwargs)\u001B[0m\n\u001B[0;32m    175\u001B[0m             \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mon_trial_begin\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtrial\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 176\u001B[1;33m             \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mrun_trial\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtrial\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m*\u001B[0m\u001B[0mfit_args\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mfit_kwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    177\u001B[0m             \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mon_trial_end\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtrial\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32md:\\finki\\40_diploma_thesis\\venv\\lib\\site-packages\\keras_tuner\\engine\\multi_execution_tuner.py\u001B[0m in \u001B[0;36mrun_trial\u001B[1;34m(self, trial, *fit_args, **fit_kwargs)\u001B[0m\n\u001B[0;32m     89\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 90\u001B[1;33m             \u001B[0mhistory\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_build_and_fit_model\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtrial\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mfit_args\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcopied_fit_kwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     91\u001B[0m             \u001B[1;32mfor\u001B[0m \u001B[0mmetric\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mepoch_values\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mhistory\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mhistory\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mitems\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32md:\\finki\\40_diploma_thesis\\venv\\lib\\site-packages\\keras_tuner\\engine\\tuner.py\u001B[0m in \u001B[0;36m_build_and_fit_model\u001B[1;34m(self, trial, fit_args, fit_kwargs)\u001B[0m\n\u001B[0;32m    148\u001B[0m         \u001B[0mmodel\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mhypermodel\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mbuild\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtrial\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mhyperparameters\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 149\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[0mmodel\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfit\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0mfit_args\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mfit_kwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    150\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32md:\\finki\\40_diploma_thesis\\venv\\lib\\site-packages\\comet_ml\\monkey_patching.py\u001B[0m in \u001B[0;36mwrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    316\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 317\u001B[1;33m         \u001B[0mreturn_value\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0moriginal\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    318\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32md:\\finki\\40_diploma_thesis\\venv\\lib\\site-packages\\keras\\engine\\training.py\u001B[0m in \u001B[0;36mfit\u001B[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001B[0m\n\u001B[0;32m   1183\u001B[0m               \u001B[0mcallbacks\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mon_train_batch_begin\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mstep\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1184\u001B[1;33m               \u001B[0mtmp_logs\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtrain_function\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0miterator\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1185\u001B[0m               \u001B[1;32mif\u001B[0m \u001B[0mdata_handler\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mshould_sync\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32md:\\finki\\40_diploma_thesis\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001B[0m in \u001B[0;36m__call__\u001B[1;34m(self, *args, **kwds)\u001B[0m\n\u001B[0;32m    884\u001B[0m       \u001B[1;32mwith\u001B[0m \u001B[0mOptionalXlaContext\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_jit_compile\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 885\u001B[1;33m         \u001B[0mresult\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_call\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwds\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    886\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32md:\\finki\\40_diploma_thesis\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001B[0m in \u001B[0;36m_call\u001B[1;34m(self, *args, **kwds)\u001B[0m\n\u001B[0;32m    916\u001B[0m       \u001B[1;31m# defunned version which is guaranteed to never create variables.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 917\u001B[1;33m       \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_stateless_fn\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwds\u001B[0m\u001B[1;33m)\u001B[0m  \u001B[1;31m# pylint: disable=not-callable\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    918\u001B[0m     \u001B[1;32melif\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_stateful_fn\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32md:\\finki\\40_diploma_thesis\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001B[0m in \u001B[0;36m__call__\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   3038\u001B[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001B[1;32m-> 3039\u001B[1;33m     return graph_function._call_flat(\n\u001B[0m\u001B[0;32m   3040\u001B[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n",
      "\u001B[1;32md:\\finki\\40_diploma_thesis\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001B[0m in \u001B[0;36m_call_flat\u001B[1;34m(self, args, captured_inputs, cancellation_manager)\u001B[0m\n\u001B[0;32m   1962\u001B[0m       \u001B[1;31m# No tape is watching; skip to running the function.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1963\u001B[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001B[0m\u001B[0;32m   1964\u001B[0m           ctx, args, cancellation_manager=cancellation_manager))\n",
      "\u001B[1;32md:\\finki\\40_diploma_thesis\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001B[0m in \u001B[0;36mcall\u001B[1;34m(self, ctx, args, cancellation_manager)\u001B[0m\n\u001B[0;32m    590\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mcancellation_manager\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 591\u001B[1;33m           outputs = execute.execute(\n\u001B[0m\u001B[0;32m    592\u001B[0m               \u001B[0mstr\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msignature\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mname\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32md:\\finki\\40_diploma_thesis\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001B[0m in \u001B[0;36mquick_execute\u001B[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001B[0m\n\u001B[0;32m     58\u001B[0m     \u001B[0mctx\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mensure_initialized\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 59\u001B[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001B[0m\u001B[0;32m     60\u001B[0m                                         inputs, attrs, num_outputs)\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "\u001B[1;32md:\\finki\\40_diploma_thesis\\venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\u001B[0m in \u001B[0;36mshowtraceback\u001B[1;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001B[0m\n\u001B[0;32m   2060\u001B[0m                         \u001B[1;31m# in the engines. This should return a list of strings.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 2061\u001B[1;33m                         \u001B[0mstb\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mvalue\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_render_traceback_\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   2062\u001B[0m                     \u001B[1;32mexcept\u001B[0m \u001B[0mException\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mAttributeError\u001B[0m: 'KeyboardInterrupt' object has no attribute '_render_traceback_'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "    \u001B[1;31m[... skipping hidden 1 frame]\u001B[0m\n",
      "\u001B[1;32md:\\finki\\40_diploma_thesis\\venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\u001B[0m in \u001B[0;36mshowtraceback\u001B[1;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001B[0m\n\u001B[0;32m   2061\u001B[0m                         \u001B[0mstb\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mvalue\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_render_traceback_\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   2062\u001B[0m                     \u001B[1;32mexcept\u001B[0m \u001B[0mException\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 2063\u001B[1;33m                         stb = self.InteractiveTB.structured_traceback(etype,\n\u001B[0m\u001B[0;32m   2064\u001B[0m                                             value, tb, tb_offset=tb_offset)\n\u001B[0;32m   2065\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32md:\\finki\\40_diploma_thesis\\venv\\lib\\site-packages\\IPython\\core\\ultratb.py\u001B[0m in \u001B[0;36mstructured_traceback\u001B[1;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001B[0m\n\u001B[0;32m   1365\u001B[0m         \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1366\u001B[0m             \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtb\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtb\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1367\u001B[1;33m         return FormattedTB.structured_traceback(\n\u001B[0m\u001B[0;32m   1368\u001B[0m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001B[0;32m   1369\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32md:\\finki\\40_diploma_thesis\\venv\\lib\\site-packages\\IPython\\core\\ultratb.py\u001B[0m in \u001B[0;36mstructured_traceback\u001B[1;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001B[0m\n\u001B[0;32m   1265\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mmode\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mverbose_modes\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1266\u001B[0m             \u001B[1;31m# Verbose modes need a full traceback\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1267\u001B[1;33m             return VerboseTB.structured_traceback(\n\u001B[0m\u001B[0;32m   1268\u001B[0m                 \u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0metype\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mvalue\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtb\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtb_offset\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnumber_of_lines_of_context\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1269\u001B[0m             )\n",
      "\u001B[1;32md:\\finki\\40_diploma_thesis\\venv\\lib\\site-packages\\IPython\\core\\ultratb.py\u001B[0m in \u001B[0;36mstructured_traceback\u001B[1;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001B[0m\n\u001B[0;32m   1122\u001B[0m         \u001B[1;34m\"\"\"Return a nice text document describing the traceback.\"\"\"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1123\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1124\u001B[1;33m         formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n\u001B[0m\u001B[0;32m   1125\u001B[0m                                                                tb_offset)\n\u001B[0;32m   1126\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32md:\\finki\\40_diploma_thesis\\venv\\lib\\site-packages\\IPython\\core\\ultratb.py\u001B[0m in \u001B[0;36mformat_exception_as_a_whole\u001B[1;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001B[0m\n\u001B[0;32m   1080\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1081\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1082\u001B[1;33m         \u001B[0mlast_unique\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mrecursion_repeat\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mfind_recursion\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0morig_etype\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mevalue\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mrecords\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1083\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1084\u001B[0m         \u001B[0mframes\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mformat_records\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mrecords\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mlast_unique\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mrecursion_repeat\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32md:\\finki\\40_diploma_thesis\\venv\\lib\\site-packages\\IPython\\core\\ultratb.py\u001B[0m in \u001B[0;36mfind_recursion\u001B[1;34m(etype, value, records)\u001B[0m\n\u001B[0;32m    380\u001B[0m     \u001B[1;31m# first frame (from in to out) that looks different.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    381\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[0mis_recursion_error\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0metype\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mvalue\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mrecords\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 382\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[0mlen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mrecords\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m0\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    383\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    384\u001B[0m     \u001B[1;31m# Select filename, lineno, func_name to track frames with\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mTypeError\u001B[0m: object of type 'NoneType' has no len()"
     ]
    }
   ],
   "source": [
    "# try:\n",
    "experiment = Experiment(\n",
    "    api_key = 'A8Lg71j9LtIrsv0deBA0DVGcR',\n",
    "    project_name = COMET_PROJECT,\n",
    "    workspace = 'diploma',\n",
    "    auto_output_logging = 'native',\n",
    ")\n",
    "experiment.set_name(f\"Bayesian\")\n",
    "experiment.add_tags(EXPERIMENT_ID.split('_'))\n",
    "\n",
    "tuner = kt.BayesianOptimization(\n",
    "    build_model,\n",
    "    objective = kt.Objective(f1_macro_func, direction=\"max\"),\n",
    "    max_trials=1000,\n",
    "    executions_per_trial=2,\n",
    "    directory=\"keras_tuner_logs\",\n",
    "    project_name=\"initial_val\",\n",
    ")\n",
    "\n",
    "with experiment.train():\n",
    "    tuner.search(x_train, y_train,\n",
    "                 epochs = 10,\n",
    "                 class_weight = class_weight,\n",
    "                 verbose = 10,\n",
    "                 validation_data = (x_val, y_val))\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "results_list = list()\n",
    "models_dir = 'saved_models'\n",
    "import os\n",
    "for model_file in os.listdir(models_dir):\n",
    "    model_i = tf.keras.models.load_model(f'{models_dir}/{model_file}',\n",
    "            custom_objects = {\n",
    "                'f1_macro_func':f1_macro_func,\n",
    "                'f1_1_func':f1_1_func,\n",
    "                'f1_0_func':f1_0_func,\n",
    "                'precision_func':precision_func,\n",
    "                'recall_func':recall_func\n",
    "             })\n",
    "\n",
    "    y_pred = model_i.predict(x_test)\n",
    "    y_pred = np.where(y_pred > 0.5, 1, 0).ravel()\n",
    "\n",
    "    test_metrics = metrics_report(y_test, y_pred)\n",
    "    print(test_metrics)\n",
    "    results_list.append(test_metrics)\n",
    "\n",
    "    for layer_i in model_i.layers:\n",
    "        try:\n",
    "            print(layer_i.kernel_size)\n",
    "        except:\n",
    "            pass"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pd.DataFrame(results_list).to_excel('results.xlsx')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%g\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}